{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text/Object Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8xko9VFRyCU/YV5AYtGeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb68518892fd416680e8336d1cfad135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0c82453c76d4db5a71571bbb9181d43",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2730c6743baf43f5857d8d617ee48040",
              "IPY_MODEL_a487024ba57b4225b593efe049d32ca8"
            ]
          }
        },
        "d0c82453c76d4db5a71571bbb9181d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2730c6743baf43f5857d8d617ee48040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e7f37b8764b4785a7b4cb78697f31a2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 167502836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 167502836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2449c78c29b747da84d4895df48de665"
          }
        },
        "a487024ba57b4225b593efe049d32ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5bd4e1ccd54b467da58cdc1ef481b1a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 160M/160M [00:04&lt;00:00, 38.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ca2f9473bef43d1b83df006f974c2a9"
          }
        },
        "9e7f37b8764b4785a7b4cb78697f31a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2449c78c29b747da84d4895df48de665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bd4e1ccd54b467da58cdc1ef481b1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ca2f9473bef43d1b83df006f974c2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakshitsakhuja/Signboard-Translation-from-Vernacular-Languages/blob/master/Text_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQQsw0zpRCik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f070a66a-d80d-49a3-ff18-51ed122e2f0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LSbTJXrRIEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Text Detection')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv39GXGNhhHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1aaac9ce-cee0-4d9a-e8e8-4b7d16bbca8d"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  2 04:58:45 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ6CJ_jrR_Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar -xvf '/content/drive/My Drive/Text Detection/Datasets/real_Image_dataset_Detection.tar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9IB-A8wbQ_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm Datasets/real_Image_dataset_Detection/Annotation/46.\\ videoblocks-india-tourism-delhi-sign-hindi-and-english-nighttime-new-delhi-india_rx3i43x6g_thumbnail-full01.txt\n",
        "# !rm Datasets/real_Image_dataset_Detection/Annotation/270.\\ palika-bazaar.txt\n",
        "# !rm Datasets/real_Image_dataset_Detection/Image/46.\\ videoblocks-india-tourism-delhi-sign-hindi-and-english-nighttime-new-delhi-india_rx3i43x6g_thumbnail-full01.jpg\n",
        "# !rm Datasets/real_Image_dataset_Detection/Image/270.\\ palika-bazaar.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtKE1pjGRJUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "bb68518892fd416680e8336d1cfad135",
            "d0c82453c76d4db5a71571bbb9181d43",
            "2730c6743baf43f5857d8d617ee48040",
            "a487024ba57b4225b593efe049d32ca8",
            "9e7f37b8764b4785a7b4cb78697f31a2",
            "2449c78c29b747da84d4895df48de665",
            "5bd4e1ccd54b467da58cdc1ef481b1a5",
            "3ca2f9473bef43d1b83df006f974c2a9"
          ]
        },
        "outputId": "9edca3ce-f469-4a3b-e244-f6361f14a22e"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from os.path import basename\n",
        "\n",
        "import torch\n",
        "\n",
        "from checkpoint import load_ckp\n",
        "from config import parameters\n",
        "from dataloader_factory import get_custom_dataset\n",
        "from models import pretrained_model\n",
        "from train import train_fn\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.makedirs('/'.join(parameters['checkpoint_path'].split('/')[:-1]), exist_ok=True)\n",
        "    os.makedirs('/'.join(parameters['best_model_path'].split('/')[:-1]), exist_ok=True)\n",
        "\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(f'Device : {device} is selected')\n",
        "    file_names = [''.join(basename(i)[:-4]) for i in\n",
        "                  glob.glob(os.path.join(parameters['image_dir'], '*'))]\n",
        "    # print(file_names)\n",
        "    train_loader, validation_loader = get_custom_dataset(file_names, parameters['train_frac'])\n",
        "\n",
        "    model = pretrained_model('fasterrcnn_resnet50_fpn')\n",
        "    model = model.to(device)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=parameters['learning_rate'],\n",
        "                                momentum=parameters['momentum'],\n",
        "                                weight_decay=parameters['weight_decay'])\n",
        "    try:\n",
        "        model, optimizer, start_epoch = load_ckp(parameters['checkpoint_path'], model, optimizer)\n",
        "    except Exception:\n",
        "        print('No Previous Checkpoint Found....Training the model from scratch')\n",
        "        start_epoch = 0\n",
        "    best_loss = 1e10\n",
        "    train_fn(start_epoch, parameters['epoch'], train_loader, validation_loader, model, device, optimizer, best_loss,parameters['checkpoint_path'],parameters['best_model_path'])\n",
        "\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb68518892fd416680e8336d1cfad135",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKG2yqkU24Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnPmt6owSRZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71e6d04a-8220-4aa0-a018-2b778dd76178"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device : cuda is selected\n",
            "Transformation Done\n",
            "426\n",
            "Starting Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration #10 loss: 0.1886848360300064\n",
            "Iteration #20 loss: 0.07751213014125824\n",
            "Iteration #30 loss: nan\n",
            "Iteration #40 loss: 0.2984048128128052\n",
            "Iteration #50 loss: 0.1489311307668686\n",
            "Iteration #60 loss: 0.17469733953475952\n",
            "Iteration #70 loss: 2.86879301071167\n",
            "Iteration #80 loss: 0.21998392045497894\n",
            "Iteration #90 loss: 2.240328073501587\n",
            "Epoch #23 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #100 loss: 0.16861438751220703\n",
            "Iteration #110 loss: nan\n",
            "Iteration #120 loss: 0.13263435661792755\n",
            "Iteration #130 loss: 0.19540539383888245\n",
            "Iteration #140 loss: 0.11648991703987122\n",
            "Iteration #150 loss: 5.731350898742676\n",
            "Iteration #160 loss: 0.1478748619556427\n",
            "Iteration #170 loss: 0.17970308661460876\n",
            "Iteration #180 loss: 0.35047447681427\n",
            "Iteration #190 loss: 0.12469891458749771\n",
            "Epoch #24 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #200 loss: 0.11974459886550903\n",
            "Iteration #210 loss: 0.14871729910373688\n",
            "Iteration #220 loss: 0.08353939652442932\n",
            "Iteration #230 loss: 0.12854193150997162\n",
            "Iteration #240 loss: 0.07292081415653229\n",
            "Iteration #250 loss: 0.09614241868257523\n",
            "Iteration #260 loss: 2.2507195472717285\n",
            "Iteration #270 loss: 0.2148037850856781\n",
            "Iteration #280 loss: 0.15148037672042847\n",
            "Epoch #25 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #290 loss: 0.17691855132579803\n",
            "Iteration #300 loss: 0.11406779289245605\n",
            "Iteration #310 loss: 0.11315304040908813\n",
            "Iteration #320 loss: 2.4843268394470215\n",
            "Iteration #330 loss: 0.24487774074077606\n",
            "Iteration #340 loss: 0.14531488716602325\n",
            "Iteration #350 loss: 2.4314589500427246\n",
            "Iteration #360 loss: 0.09877458214759827\n",
            "Iteration #370 loss: 1.8626296520233154\n",
            "Iteration #380 loss: 0.08599903434515\n",
            "Epoch #26 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #390 loss: 0.05785928666591644\n",
            "Iteration #400 loss: 1.6973567008972168\n",
            "Iteration #410 loss: 0.09731361269950867\n",
            "Iteration #420 loss: 0.16832755506038666\n",
            "Iteration #430 loss: 0.06973977386951447\n",
            "Iteration #440 loss: 0.12124320864677429\n",
            "Iteration #450 loss: 0.052430372685194016\n",
            "Iteration #460 loss: 0.07036066055297852\n",
            "Iteration #470 loss: 0.10037365555763245\n",
            "Iteration #480 loss: 2.7715394496917725\n",
            "Epoch #27 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #490 loss: 0.08223463594913483\n",
            "Iteration #500 loss: 0.1451064646244049\n",
            "Iteration #510 loss: 2.145237922668457\n",
            "Iteration #520 loss: 0.21284902095794678\n",
            "Iteration #530 loss: 0.07370680570602417\n",
            "Iteration #540 loss: 0.08593422174453735\n",
            "Iteration #550 loss: 0.08628853410482407\n",
            "Iteration #560 loss: nan\n",
            "Iteration #570 loss: 0.07099872827529907\n",
            "Epoch #28 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #580 loss: 0.11674747616052628\n",
            "Iteration #590 loss: 0.07089456915855408\n",
            "Iteration #600 loss: 0.1351386159658432\n",
            "Iteration #610 loss: 0.09609687328338623\n",
            "Iteration #620 loss: 0.06726627796888351\n",
            "Iteration #630 loss: 0.1600886583328247\n",
            "Iteration #640 loss: 0.19728779792785645\n",
            "Iteration #650 loss: 0.09615673869848251\n",
            "Iteration #660 loss: 0.04809414595365524\n",
            "Iteration #670 loss: 0.10089336335659027\n",
            "Epoch #29 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #680 loss: 0.1579548716545105\n",
            "Iteration #690 loss: 0.10629386454820633\n",
            "Iteration #700 loss: 0.0800171047449112\n",
            "Iteration #710 loss: 0.10332821309566498\n",
            "Iteration #720 loss: 0.12790021300315857\n",
            "Iteration #730 loss: 0.04560857266187668\n",
            "Iteration #740 loss: 0.08465814590454102\n",
            "Iteration #750 loss: 0.06945821642875671\n",
            "Iteration #760 loss: 0.09152118861675262\n",
            "Epoch #30 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #770 loss: 0.08685049414634705\n",
            "Iteration #780 loss: 0.0689127966761589\n",
            "Iteration #790 loss: 0.08905630558729172\n",
            "Iteration #800 loss: 0.10565242171287537\n",
            "Iteration #810 loss: 0.09087063372135162\n",
            "Iteration #820 loss: 0.09339404106140137\n",
            "Iteration #830 loss: 1.3103420734405518\n",
            "Iteration #840 loss: 0.06399405747652054\n",
            "Iteration #850 loss: 1.7627646923065186\n",
            "Iteration #860 loss: 0.2927010953426361\n",
            "Epoch #31 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #870 loss: 0.20898576080799103\n",
            "Iteration #880 loss: 0.06404304504394531\n",
            "Iteration #890 loss: 0.07611451297998428\n",
            "Iteration #900 loss: 0.12107519060373306\n",
            "Iteration #910 loss: nan\n",
            "Iteration #920 loss: 1.867814540863037\n",
            "Iteration #930 loss: 0.10168967396020889\n",
            "Iteration #940 loss: 0.0782267227768898\n",
            "Iteration #950 loss: 0.06605109572410583\n",
            "Iteration #960 loss: 0.13670362532138824\n",
            "Epoch #32 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #970 loss: 0.05398090183734894\n",
            "Iteration #980 loss: 0.03655567765235901\n",
            "Iteration #990 loss: 0.07592051476240158\n",
            "Iteration #1000 loss: 0.09349067509174347\n",
            "Iteration #1010 loss: 0.07465251535177231\n",
            "Iteration #1020 loss: 0.06128248572349548\n",
            "Iteration #1030 loss: 0.0675312802195549\n",
            "Iteration #1040 loss: 0.039897557348012924\n",
            "Iteration #1050 loss: 0.11458177864551544\n",
            "Epoch #33 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1060 loss: 0.04330231621861458\n",
            "Iteration #1070 loss: 0.12047252058982849\n",
            "Iteration #1080 loss: 0.059027381241321564\n",
            "Iteration #1090 loss: 0.08938750624656677\n",
            "Iteration #1100 loss: 1.3745522499084473\n",
            "Iteration #1110 loss: 0.06927330791950226\n",
            "Iteration #1120 loss: 0.11592502146959305\n",
            "Iteration #1130 loss: 0.08481694757938385\n",
            "Iteration #1140 loss: 0.07646064460277557\n",
            "Iteration #1150 loss: 0.09586906433105469\n",
            "Epoch #34 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1160 loss: 0.044882867485284805\n",
            "Iteration #1170 loss: 0.0417015440762043\n",
            "Iteration #1180 loss: 0.0634952038526535\n",
            "Iteration #1190 loss: 0.05227305740118027\n",
            "Iteration #1200 loss: 0.06987928599119186\n",
            "Iteration #1210 loss: 0.09851644933223724\n",
            "Iteration #1220 loss: 0.07042984664440155\n",
            "Iteration #1230 loss: 0.04836352914571762\n",
            "Iteration #1240 loss: 0.12554362416267395\n",
            "Epoch #35 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1250 loss: 0.29485252499580383\n",
            "Iteration #1260 loss: 0.07498734444379807\n",
            "Iteration #1270 loss: 0.06425116211175919\n",
            "Iteration #1280 loss: 0.07315632700920105\n",
            "Iteration #1290 loss: 0.08489669859409332\n",
            "Iteration #1300 loss: 0.06724857538938522\n",
            "Iteration #1310 loss: 0.07604381442070007\n",
            "Iteration #1320 loss: 0.0879892110824585\n",
            "Iteration #1330 loss: 0.07964148372411728\n",
            "Iteration #1340 loss: 1.258815050125122\n",
            "Epoch #36 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1350 loss: 0.08284255117177963\n",
            "Iteration #1360 loss: 0.04703772813081741\n",
            "Iteration #1370 loss: 0.08722703903913498\n",
            "Iteration #1380 loss: 0.09638246893882751\n",
            "Iteration #1390 loss: 0.07514011859893799\n",
            "Iteration #1400 loss: 0.06274691224098206\n",
            "Iteration #1410 loss: 0.06497737765312195\n",
            "Iteration #1420 loss: nan\n",
            "Iteration #1430 loss: 0.11182451248168945\n",
            "Iteration #1440 loss: 0.03620978444814682\n",
            "Epoch #37 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1450 loss: 0.07525245100259781\n",
            "Iteration #1460 loss: 1.6090728044509888\n",
            "Iteration #1470 loss: 0.047211796045303345\n",
            "Iteration #1480 loss: 0.13361157476902008\n",
            "Iteration #1490 loss: 0.07416031509637833\n",
            "Iteration #1500 loss: 0.12515205144882202\n",
            "Iteration #1510 loss: 0.07347159087657928\n",
            "Iteration #1520 loss: 0.07926011085510254\n",
            "Iteration #1530 loss: 0.056040674448013306\n",
            "Epoch #38 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1540 loss: 0.06029072403907776\n",
            "Iteration #1550 loss: 0.06213314086198807\n",
            "Iteration #1560 loss: 0.09599440544843674\n",
            "Iteration #1570 loss: 0.0831461101770401\n",
            "Iteration #1580 loss: 0.07181406766176224\n",
            "Iteration #1590 loss: 0.0977746993303299\n",
            "Iteration #1600 loss: 0.06705654412508011\n",
            "Iteration #1610 loss: 1.2037776708602905\n",
            "Iteration #1620 loss: 0.04925817251205444\n",
            "Iteration #1630 loss: 0.9556586146354675\n",
            "Epoch #39 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1640 loss: nan\n",
            "Iteration #1650 loss: 0.061804406344890594\n",
            "Iteration #1660 loss: 0.054716188460588455\n",
            "Iteration #1670 loss: 0.07348956167697906\n",
            "Iteration #1680 loss: 0.07356013357639313\n",
            "Iteration #1690 loss: 0.0757979229092598\n",
            "Iteration #1700 loss: 0.09927103668451309\n",
            "Iteration #1710 loss: 0.1236673891544342\n",
            "Iteration #1720 loss: 0.04645112529397011\n",
            "Epoch #40 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1730 loss: 0.05714474245905876\n",
            "Iteration #1740 loss: 0.1299939751625061\n",
            "Iteration #1750 loss: 0.04662145674228668\n",
            "Iteration #1760 loss: 0.11722908914089203\n",
            "Iteration #1770 loss: 0.033781275153160095\n",
            "Iteration #1780 loss: 0.06348852068185806\n",
            "Iteration #1790 loss: 0.05666348338127136\n",
            "Iteration #1800 loss: 0.059764314442873\n",
            "Iteration #1810 loss: 0.06499770283699036\n",
            "Iteration #1820 loss: 0.07202741503715515\n",
            "Epoch #41 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1830 loss: 0.0515705943107605\n",
            "Iteration #1840 loss: 0.06274179369211197\n",
            "Iteration #1850 loss: 1.0717352628707886\n",
            "Iteration #1860 loss: 1.3042770624160767\n",
            "Iteration #1870 loss: 0.08855807781219482\n",
            "Iteration #1880 loss: 0.049760181456804276\n",
            "Iteration #1890 loss: 0.0517064705491066\n",
            "Iteration #1900 loss: 0.04801812022924423\n",
            "Iteration #1910 loss: 0.06120773032307625\n",
            "Iteration #1920 loss: 0.06482218950986862\n",
            "Epoch #42 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #1930 loss: 0.12158356606960297\n",
            "Iteration #1940 loss: 0.07573550939559937\n",
            "Iteration #1950 loss: 0.08813980966806412\n",
            "Iteration #1960 loss: 0.06716981530189514\n",
            "Iteration #1970 loss: 0.06375393271446228\n",
            "Iteration #1980 loss: 0.04877334088087082\n",
            "Iteration #1990 loss: 0.07621289789676666\n",
            "Iteration #2000 loss: 0.045724399387836456\n",
            "Iteration #2010 loss: 0.1174691915512085\n",
            "Epoch #43 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2020 loss: 0.046259887516498566\n",
            "Iteration #2030 loss: 0.07130015641450882\n",
            "Iteration #2040 loss: 0.06618428230285645\n",
            "Iteration #2050 loss: 0.07371491938829422\n",
            "Iteration #2060 loss: 0.09674593806266785\n",
            "Iteration #2070 loss: 0.07516917586326599\n",
            "Iteration #2080 loss: 0.08549723029136658\n",
            "Iteration #2090 loss: 0.07856578379869461\n",
            "Iteration #2100 loss: 0.10766898840665817\n",
            "Iteration #2110 loss: 0.0847172960639\n",
            "Epoch #44 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2120 loss: 0.12033051252365112\n",
            "Iteration #2130 loss: 0.13285794854164124\n",
            "Iteration #2140 loss: 0.06039191409945488\n",
            "Iteration #2150 loss: 0.08706546574831009\n",
            "Iteration #2160 loss: 0.11063232272863388\n",
            "Iteration #2170 loss: 0.07537413388490677\n",
            "Iteration #2180 loss: 0.0628809705376625\n",
            "Iteration #2190 loss: 0.07428281009197235\n",
            "Iteration #2200 loss: 0.0919749066233635\n",
            "Epoch #45 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2210 loss: 0.044197045266628265\n",
            "Iteration #2220 loss: 0.037289027124643326\n",
            "Iteration #2230 loss: 0.033862967044115067\n",
            "Iteration #2240 loss: nan\n",
            "Iteration #2250 loss: 0.09585064649581909\n",
            "Iteration #2260 loss: 0.0713096410036087\n",
            "Iteration #2270 loss: 0.09612877666950226\n",
            "Iteration #2280 loss: 0.05829359591007233\n",
            "Iteration #2290 loss: nan\n",
            "Iteration #2300 loss: 0.05879916623234749\n",
            "Epoch #46 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2310 loss: 0.09696601331233978\n",
            "Iteration #2320 loss: nan\n",
            "Iteration #2330 loss: 1.1242424249649048\n",
            "Iteration #2340 loss: 0.07643617689609528\n",
            "Iteration #2350 loss: 0.041869230568408966\n",
            "Iteration #2360 loss: 1.3238117694854736\n",
            "Iteration #2370 loss: 1.4205678701400757\n",
            "Iteration #2380 loss: 0.0683942511677742\n",
            "Iteration #2390 loss: 0.046749699860811234\n",
            "Iteration #2400 loss: 0.04767446592450142\n",
            "Epoch #47 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2410 loss: 0.06184638664126396\n",
            "Iteration #2420 loss: nan\n",
            "Iteration #2430 loss: 0.0745948925614357\n",
            "Iteration #2440 loss: 0.04673624038696289\n",
            "Iteration #2450 loss: 0.09417445212602615\n",
            "Iteration #2460 loss: 0.12090999633073807\n",
            "Iteration #2470 loss: 0.10858696699142456\n",
            "Iteration #2480 loss: 0.06534728407859802\n",
            "Iteration #2490 loss: 0.06746251881122589\n",
            "Epoch #48 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2500 loss: 0.06974443793296814\n",
            "Iteration #2510 loss: 0.03775012493133545\n",
            "Iteration #2520 loss: 0.0904567539691925\n",
            "Iteration #2530 loss: 0.06295087188482285\n",
            "Iteration #2540 loss: 0.07799878716468811\n",
            "Iteration #2550 loss: 0.04777754843235016\n",
            "Iteration #2560 loss: nan\n",
            "Iteration #2570 loss: 0.09667110443115234\n",
            "Iteration #2580 loss: 0.04209311306476593\n",
            "Iteration #2590 loss: 2.7772836685180664\n",
            "Epoch #49 Train loss: nan, Validation Loss : Commented\n",
            "Iteration #2600 loss: 0.07403463125228882\n",
            "Iteration #2610 loss: 0.21212905645370483\n",
            "Iteration #2620 loss: 0.10500689595937729\n",
            "Iteration #2630 loss: 0.28552016615867615\n",
            "Iteration #2640 loss: 1.2963943481445312\n",
            "Iteration #2650 loss: 0.08148309588432312\n",
            "Iteration #2660 loss: 0.06190362572669983\n",
            "Iteration #2670 loss: nan\n",
            "Iteration #2680 loss: 0.1411917507648468\n",
            "Epoch #50 Train loss: nan, Validation Loss : Commented\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5CW1De4UOBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters['image_dir']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q35cM6iRUll1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "67726527-1b1c-475d-ea7d-8330a34a38fb"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Device : {device} is selected')\n",
        "file_names = [''.join(basename(i)[:-4]) for i in\n",
        "                  glob.glob(os.path.join(parameters['image_dir'], '*'))]\n",
        "    # print(file_names)\n",
        "train_loader, validation_loader = get_custom_dataset(file_names, parameters['train_frac'])\n",
        "\n",
        "model = pretrained_model('fasterrcnn_resnet50_fpn')\n",
        "model = model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=parameters['learning_rate'],\n",
        "                                momentum=parameters['momentum'],\n",
        "                                weight_decay=parameters['weight_decay'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device : cuda is selected\n",
            "Transformation Done\n",
            "426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AikSwEcEzhMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbb99aed-bf15-4327-8a16-edcb0746816e"
      },
      "source": [
        "load_ckp(checkpoint_fpath = parameters['checkpoint_path'], model=model, optimizer = optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(FasterRCNN(\n",
              "   (transform): GeneralizedRCNNTransform(\n",
              "       Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "       Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "   )\n",
              "   (backbone): BackboneWithFPN(\n",
              "     (body): IntermediateLayerGetter(\n",
              "       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "       (bn1): FrozenBatchNorm2d()\n",
              "       (relu): ReLU(inplace=True)\n",
              "       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "       (layer1): Sequential(\n",
              "         (0): Bottleneck(\n",
              "           (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "           (downsample): Sequential(\n",
              "             (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): FrozenBatchNorm2d()\n",
              "           )\n",
              "         )\n",
              "         (1): Bottleneck(\n",
              "           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (2): Bottleneck(\n",
              "           (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "       )\n",
              "       (layer2): Sequential(\n",
              "         (0): Bottleneck(\n",
              "           (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "           (downsample): Sequential(\n",
              "             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "             (1): FrozenBatchNorm2d()\n",
              "           )\n",
              "         )\n",
              "         (1): Bottleneck(\n",
              "           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (2): Bottleneck(\n",
              "           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (3): Bottleneck(\n",
              "           (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "       )\n",
              "       (layer3): Sequential(\n",
              "         (0): Bottleneck(\n",
              "           (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "           (downsample): Sequential(\n",
              "             (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "             (1): FrozenBatchNorm2d()\n",
              "           )\n",
              "         )\n",
              "         (1): Bottleneck(\n",
              "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (2): Bottleneck(\n",
              "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (3): Bottleneck(\n",
              "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (4): Bottleneck(\n",
              "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (5): Bottleneck(\n",
              "           (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "       )\n",
              "       (layer4): Sequential(\n",
              "         (0): Bottleneck(\n",
              "           (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "           (downsample): Sequential(\n",
              "             (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "             (1): FrozenBatchNorm2d()\n",
              "           )\n",
              "         )\n",
              "         (1): Bottleneck(\n",
              "           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "         (2): Bottleneck(\n",
              "           (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn1): FrozenBatchNorm2d()\n",
              "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "           (bn2): FrozenBatchNorm2d()\n",
              "           (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (bn3): FrozenBatchNorm2d()\n",
              "           (relu): ReLU(inplace=True)\n",
              "         )\n",
              "       )\n",
              "     )\n",
              "     (fpn): FeaturePyramidNetwork(\n",
              "       (inner_blocks): ModuleList(\n",
              "         (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "         (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "         (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "         (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "       )\n",
              "       (layer_blocks): ModuleList(\n",
              "         (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "         (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "         (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "         (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "       )\n",
              "       (extra_blocks): LastLevelMaxPool()\n",
              "     )\n",
              "   )\n",
              "   (rpn): RegionProposalNetwork(\n",
              "     (anchor_generator): AnchorGenerator()\n",
              "     (head): RPNHead(\n",
              "       (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "       (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "       (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "     )\n",
              "   )\n",
              "   (roi_heads): RoIHeads(\n",
              "     (box_roi_pool): MultiScaleRoIAlign()\n",
              "     (box_head): TwoMLPHead(\n",
              "       (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "       (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "     )\n",
              "     (box_predictor): FastRCNNPredictor(\n",
              "       (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "       (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "     )\n",
              "   )\n",
              " ), SGD (\n",
              " Parameter Group 0\n",
              "     dampening: 0\n",
              "     lr: 0.005\n",
              "     momentum: 0.9\n",
              "     nesterov: False\n",
              "     weight_decay: 0.0005\n",
              " ), 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LeEelVB3DMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f13b427d-f76c-4c86-8529-7a28f7e6e309"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}